d$sex <- as.factor(d$sex)
d$psyKnowledge <- as.factor(d$psyKnowledge)
d$education <- as.factor(d$education)
d$handedness <- as.factor(d$handedness)
d$motherTongue <- as.factor(d$motherTongue)
d$country <- as.factor(d$country)
d$prolific <- as.factor(d$prolific)
#d$map_horiAA300 <- as.factor(d$map_horiAA300)
d$rt <- as.numeric(d$rt)
# Prepare the 2 datsets for RTs and errors analyses -------------------------------------------------------
# create a column useful afterwards
d$respRepetitions <- 0
# fix the missing values of sex and handedness (1 pp) with most likely value
d$handedness[d$handedness == "Other (please specify)"] <- "right-handed"
d$sex[d$sex == "I'd rather not say"] <- "male"
# dataset clening for rts analyses
cat("Fast trials were", sum(d$rt < 200), "\n")
drt <- d[(d$task_R != 99 & d$rt > 200 & !is.na(d$Attempt == 1)),]
drt <- drt[!(drt$error == 1 | drt$error_R == 1),]
cat("In total removed", (dim(d)[1] - dim(drt)[1])/dim(d)[1], "of the observations \n")
for (j in unique(drt$pp)){
drt[drt$pp == j, "respRepetitions"] <- sum(drt$pp == j & drt$ANSWER_R == 0)
}
# dataset cleaing for error analyses
de <- d[d$task_R != 99 & d$rt > 200,]
# count resp repetitions
for (j in unique(de$pp)){
de[de$pp == j, "respRepetitions"] <- sum(de$pp == j & de$ANSWER_R == 0)
}
drt$respRepetitions <- as.numeric(drt$respRepetition)
de$respRepetitions <- as.numeric(de$respRepetition)
# stadardize these for error model --> helps it to converge
de$respRepetitions <- (de$respRepetitions - mean(de$respRepetitions))/sd(de$respRepetitions)
# Plot errors distribution across pps -----------------------------------------------------------------------
# calculate mean for each pp
errM <- group_my(d, error, pp, task_R, ANSWER_R, context_R, cocoa)
pps <- group_my(errM, meanerror, pp)
cat("Mean error rate was",  mean(pps$meanmeanerror), "plus or minus", sd(pps$meanmeanerror))
png(paste0(figDir, B, "_errorsDistr", ".png"), width = 1500, height = 1000, res = 200)
hist(pps$meanmeanerror, col=45, main = "Distribution of error rates", xlab= "error rate",
breaks = seq(0,0.3,0.01))
abline(v= mean(pps$meanmeanerror) + sd(pps$meanmeanerror)*2, col= "darkblue", lwd= 2, lty = "dashed")
dev.off()
# Remove outliers -------------------------------------------------------------------------------------------
# who are the worst ones
ppsWorse <- as.data.frame(pps[pps$meanmeanerror > (mean(pps$meanmeanerror) + sd(pps$meanmeanerror)*2), "pp"])
for (ppRem in ppsWorse$pp){
#print(ppRem)
drt <- drt[!drt$pp == ppRem, ]
de <- de[!de$pp == ppRem, ]
}
# Distribution
mod2 <- lmer(log(rt) ~ task_R*ANSWER_R*context_R*cocoa + ANSWER_R*congruency + blockNum + sex +
Participant.Browser + Participant.OS +handedness + prolific + respRepetitions +
(1|pp) + (1|stimulus), data= drt, REML=F)
summary(mod2)
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
d[1:100, c("congruency", "congruency_post")]
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
sum(is.na(d$trialNum))
577/96
v <- c(577,769,961, 1057)
v%%96
577*6
96*6
min(d$trialNum)
sum(v%%96 != 0)
d[577,]
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
# Load packages -------------------------------
if(!require(pacman)) install.packages("pacman")
pacman::p_load("haven", "dplyr", "lme4", "reshape2", "ggplot2", "wesanderson", "afex", "emmeans", "tables")
select <- dplyr::select
filter <- dplyr::filter
# parameter for graphs
pd = position_dodge(.1)
# write the path to your project folder
setwd('C://Users//Elena//Documents//AA_PhD//Projects//BRAC01_BRAC02//BRAC01-FirstOnline')
# define paths to further subfolders in the project folders (create them first)
dataDir = "data//"
figDir = "figures//"
tabDir = "tables//"
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# Load and prepare Data ----------------------------------------------------------------------------------------
#B = "B1B2"
#B = "B1"
B = "B2"
# Load B1 and pick 2 people form rwth only ----------------------------------------------------------------------
d_pro <- read.csv(paste0(dataDir, "B1_Pro", ".csv"), sep = ";", dec = ",")
d_pro$prolific <- 1
d_rwth <- read.csv(paste0(dataDir, "B1_RWTH", ".csv"), sep = ";", dec = ",")
d_rwth$prolific <- 0
# Pick 2 pps with horiAA_1st300
# We got too many with same counterbalance:
# I pick LU1 and LY8, the first male and a female with no warnings in the logbook
rwthLB <- read.csv2(paste0(tabDir, "logbook_B1_RWTH", ".csv"))
pps2keep <- rwthLB[rwthLB$mapping != "BRAC1_horiAA_1st300" | rwthLB$pp == "LU1" | rwthLB$pp == "LY8", "pp"]
pps2rem <- setdiff(unique(d_rwth$pp), pps2keep)
for (ppRem in pps2rem){
d_rwth <- d_rwth[!d_rwth$pp == ppRem, ]
}
d1 <- rbind(d_rwth, d_pro)
names(d1)[names(d1) == "cuecolor_R"] <- "context_R"
d1$exp <- "BRAC1"
# Load BRAC2 ---------------------------------------------------------------------------------------------
d_pro2 <- read.csv(paste0(dataDir, "B2_Pro", ".csv"), sep = ";", dec = ",")
d_pro2$prolific <- 1
d_rwth2 <- read.csv(paste0(dataDir, "B2_RWTH", ".csv"), sep = ";", dec = ",")
d_rwth2$prolific <- 0
d2 <- rbind(d_rwth2, d_pro2)
names(d2)[names(d2) == "framecolor_R"] <- "context_R"
d2$exp <- "BRAC2"
dtot <- rbind(d1, d2)
# Subset the dataset based on the B
if(B == "B1"){d <- dtot[dtot$exp == "BRAC1",]
}else if (B == "B2"){d <- dtot[dtot$exp == "BRAC2",]
}else if (B== "B1B2"){d <- dtot}
rownames(d)
rownames(d) <- NULL
rownames(d)
# Add more variables ---------------------------------------------------------------------------------------
# Congruency
d$congruency <- 99
for (i in 1:dim(d)[1]){
currPP = d[i, "pp"]
currStim = d[i, "stimulus"]
currTask = d[i, "task"]
if (unique(d[d$pp == currPP & d$stimulus == currStim & d$task != currTask, "ANSWER"]) == d[i, "ANSWER"]){
d$congruency[i] <- 1
} else {
d$congruency[i] <- 0
}
}
d$congruency <- as.factor(d$congruency)
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
576/96
d[576, "trialNum"]
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
d[576,]
d[29183,]
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
d$congruency_post <- as.factor(d$congruency_post)
# Change variables class ---------------------------------------------------------------------------------------
d$task_R <- as.factor(d$task_R)
d$ANSWER_R <- as.factor(d$ANSWER_R)
d$context_R <- as.factor(d$context_R)
d$Attempt <- as.factor(d$Attempt)
d$cocoa <- as.factor(d$cocoa)
d$counterbalance <- as.factor(d$counterbalance)
d$age <- as.numeric(d$age)
d$sex <- as.factor(d$sex)
d$psyKnowledge <- as.factor(d$psyKnowledge)
d$education <- as.factor(d$education)
d$handedness <- as.factor(d$handedness)
d$motherTongue <- as.factor(d$motherTongue)
d$country <- as.factor(d$country)
d$prolific <- as.factor(d$prolific)
#d$map_horiAA300 <- as.factor(d$map_horiAA300)
d$rt <- as.numeric(d$rt)
# Prepare the 2 datsets for RTs and errors analyses -------------------------------------------------------
# create a column useful afterwards
d$respRepetitions <- 0
# fix the missing values of sex and handedness (1 pp) with most likely value
d$handedness[d$handedness == "Other (please specify)"] <- "right-handed"
d$sex[d$sex == "I'd rather not say"] <- "male"
# dataset clening for rts analyses
cat("Fast trials were", sum(d$rt < 200), "\n")
drt <- d[(d$task_R != 99 & d$rt > 200 & !is.na(d$Attempt == 1)),]
drt <- drt[!(drt$error == 1 | drt$error_R == 1),]
cat("In total removed", (dim(d)[1] - dim(drt)[1])/dim(d)[1], "of the observations \n")
for (j in unique(drt$pp)){
drt[drt$pp == j, "respRepetitions"] <- sum(drt$pp == j & drt$ANSWER_R == 0)
}
# dataset cleaing for error analyses
de <- d[d$task_R != 99 & d$rt > 200,]
# count resp repetitions
for (j in unique(de$pp)){
de[de$pp == j, "respRepetitions"] <- sum(de$pp == j & de$ANSWER_R == 0)
}
drt$respRepetitions <- as.numeric(drt$respRepetition)
de$respRepetitions <- as.numeric(de$respRepetition)
# stadardize these for error model --> helps it to converge
de$respRepetitions <- (de$respRepetitions - mean(de$respRepetitions))/sd(de$respRepetitions)
# Plot errors distribution across pps -----------------------------------------------------------------------
# calculate mean for each pp
errM <- group_my(d, error, pp, task_R, ANSWER_R, context_R, cocoa)
pps <- group_my(errM, meanerror, pp)
cat("Mean error rate was",  mean(pps$meanmeanerror), "plus or minus", sd(pps$meanmeanerror))
png(paste0(figDir, B, "_errorsDistr", ".png"), width = 1500, height = 1000, res = 200)
hist(pps$meanmeanerror, col=45, main = "Distribution of error rates", xlab= "error rate",
breaks = seq(0,0.3,0.01))
abline(v= mean(pps$meanmeanerror) + sd(pps$meanmeanerror)*2, col= "darkblue", lwd= 2, lty = "dashed")
dev.off()
# Remove outliers -------------------------------------------------------------------------------------------
# who are the worst ones
ppsWorse <- as.data.frame(pps[pps$meanmeanerror > (mean(pps$meanmeanerror) + sd(pps$meanmeanerror)*2), "pp"])
for (ppRem in ppsWorse$pp){
#print(ppRem)
drt <- drt[!drt$pp == ppRem, ]
de <- de[!de$pp == ppRem, ]
}
# Distributi
B
mod2tris <- lmer(log(rt) ~ task_R*ANSWER_R*context_R*cocoa + ANSWER_R*congruency_post + blockNum + sex +
Participant.Browser + Participant.OS +handedness + prolific + respRepetitions +
(1|pp) + (1|stimulus), data= drt, REML=F)
summary(mod2tris)
# Load packages -------------------------------
if(!require(pacman)) install.packages("pacman")
pacman::p_load("haven", "dplyr", "lme4", "reshape2", "ggplot2", "wesanderson", "afex", "emmeans", "tables")
select <- dplyr::select
filter <- dplyr::filter
# parameter for graphs
pd = position_dodge(.1)
# write the path to your project folder
setwd('C://Users//Elena//Documents//AA_PhD//Projects//BRAC01_BRAC02//BRAC01-FirstOnline')
# define paths to further subfolders in the project folders (create them first)
dataDir = "data//"
figDir = "figures//"
tabDir = "tables//"
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
# Load and prepare Data ----------------------------------------------------------------------------------------
#B = "B1B2"
B = "B1"
#B = "B2"
# Load B1 and pick 2 people form rwth only ----------------------------------------------------------------------
d_pro <- read.csv(paste0(dataDir, "B1_Pro", ".csv"), sep = ";", dec = ",")
d_pro$prolific <- 1
d_rwth <- read.csv(paste0(dataDir, "B1_RWTH", ".csv"), sep = ";", dec = ",")
d_rwth$prolific <- 0
# Pick 2 pps with horiAA_1st300
# We got too many with same counterbalance:
# I pick LU1 and LY8, the first male and a female with no warnings in the logbook
rwthLB <- read.csv2(paste0(tabDir, "logbook_B1_RWTH", ".csv"))
pps2keep <- rwthLB[rwthLB$mapping != "BRAC1_horiAA_1st300" | rwthLB$pp == "LU1" | rwthLB$pp == "LY8", "pp"]
pps2rem <- setdiff(unique(d_rwth$pp), pps2keep)
for (ppRem in pps2rem){
d_rwth <- d_rwth[!d_rwth$pp == ppRem, ]
}
d1 <- rbind(d_rwth, d_pro)
names(d1)[names(d1) == "cuecolor_R"] <- "context_R"
d1$exp <- "BRAC1"
# Load BRAC2 ---------------------------------------------------------------------------------------------
d_pro2 <- read.csv(paste0(dataDir, "B2_Pro", ".csv"), sep = ";", dec = ",")
d_pro2$prolific <- 1
d_rwth2 <- read.csv(paste0(dataDir, "B2_RWTH", ".csv"), sep = ";", dec = ",")
d_rwth2$prolific <- 0
d2 <- rbind(d_rwth2, d_pro2)
names(d2)[names(d2) == "framecolor_R"] <- "context_R"
d2$exp <- "BRAC2"
dtot <- rbind(d1, d2)
# Subset the dataset based on the B
if(B == "B1"){d <- dtot[dtot$exp == "BRAC1",]
}else if (B == "B2"){d <- dtot[dtot$exp == "BRAC2",]
}else if (B== "B1B2"){d <- dtot}
rownames(d) <- NULL
# Add more variables ---------------------------------------------------------------------------------------
# Congruency
d$congruency <- 99
for (i in 1:dim(d)[1]){
currPP = d[i, "pp"]
currStim = d[i, "stimulus"]
currTask = d[i, "task"]
if (unique(d[d$pp == currPP & d$stimulus == currStim & d$task != currTask, "ANSWER"]) == d[i, "ANSWER"]){
d$congruency[i] <- 1
} else {
d$congruency[i] <- 0
}
}
d$congruency <- as.factor(d$congruency)
# if previous trial was congruent or not
d <- sequence_relation(d, "congruency", 96, suffix = "post", Lag = 1, type = "error")
d$congruency_post <- as.factor(d$congruency_post)
# Change variables class ---------------------------------------------------------------------------------------
d$task_R <- as.factor(d$task_R)
d$ANSWER_R <- as.factor(d$ANSWER_R)
d$context_R <- as.factor(d$context_R)
d$Attempt <- as.factor(d$Attempt)
d$cocoa <- as.factor(d$cocoa)
d$counterbalance <- as.factor(d$counterbalance)
d$age <- as.numeric(d$age)
d$sex <- as.factor(d$sex)
d$psyKnowledge <- as.factor(d$psyKnowledge)
d$education <- as.factor(d$education)
d$handedness <- as.factor(d$handedness)
d$motherTongue <- as.factor(d$motherTongue)
d$country <- as.factor(d$country)
d$prolific <- as.factor(d$prolific)
#d$map_horiAA300 <- as.factor(d$map_horiAA300)
d$rt <- as.numeric(d$rt)
# Prepare the 2 datsets for RTs and errors analyses -------------------------------------------------------
# create a column useful afterwards
d$respRepetitions <- 0
# fix the missing values of sex and handedness (1 pp) with most likely value
d$handedness[d$handedness == "Other (please specify)"] <- "right-handed"
d$sex[d$sex == "I'd rather not say"] <- "male"
# dataset clening for rts analyses
cat("Fast trials were", sum(d$rt < 200), "\n")
drt <- d[(d$task_R != 99 & d$rt > 200 & !is.na(d$Attempt == 1)),]
drt <- drt[!(drt$error == 1 | drt$error_R == 1),]
cat("In total removed", (dim(d)[1] - dim(drt)[1])/dim(d)[1], "of the observations \n")
for (j in unique(drt$pp)){
drt[drt$pp == j, "respRepetitions"] <- sum(drt$pp == j & drt$ANSWER_R == 0)
}
# dataset cleaing for error analyses
de <- d[d$task_R != 99 & d$rt > 200,]
# count resp repetitions
for (j in unique(de$pp)){
de[de$pp == j, "respRepetitions"] <- sum(de$pp == j & de$ANSWER_R == 0)
}
drt$respRepetitions <- as.numeric(drt$respRepetition)
de$respRepetitions <- as.numeric(de$respRepetition)
# stadardize these for error model --> helps it to converge
de$respRepetitions <- (de$respRepetitions - mean(de$respRepetitions))/sd(de$respRepetitions)
# Plot errors distribution across pps -----------------------------------------------------------------------
# calculate mean for each pp
errM <- group_my(d, error, pp, task_R, ANSWER_R, context_R, cocoa)
pps <- group_my(errM, meanerror, pp)
cat("Mean error rate was",  mean(pps$meanmeanerror), "plus or minus", sd(pps$meanmeanerror))
png(paste0(figDir, B, "_errorsDistr", ".png"), width = 1500, height = 1000, res = 200)
hist(pps$meanmeanerror, col=45, main = "Distribution of error rates", xlab= "error rate",
breaks = seq(0,0.3,0.01))
abline(v= mean(pps$meanmeanerror) + sd(pps$meanmeanerror)*2, col= "darkblue", lwd= 2, lty = "dashed")
dev.off()
# Remove outliers -------------------------------------------------------------------------------------------
# who are the worst ones
ppsWorse <- as.data.frame(pps[pps$meanmeanerror > (mean(pps$meanmeanerror) + sd(pps$meanmeanerror)*2), "pp"])
for (ppRem in ppsWorse$pp){
#print(ppRem)
drt <- drt[!drt$pp == ppRem, ]
de <- de[!de$pp == ppRem, ]
}
# Distribution RTs
# either country or prolific, not both
mod2 <- lmer(log(rt) ~ task_R*ANSWER_R*context_R*cocoa + blockNum + sex + Participant.Browser +
Participant.OS +handedness + prolific + respRepetitions + (1|pp) + (1|stimulus),
data= drt, REML=F)
# Prepare Contrasts RTs ---------------------------------------------------------------------------------------
# Build custom contrasts
# https://aosmith.rbind.io/2019/04/15/custom-contrasts-emmeans/
# Compare the Delta of the task sw cost in resp rep and resp sw --> same as interaction of the mdel
# take the estMeans and build vectors that "pick" the specific condition
trep <- rep(0, 16)
trep[seq(1, 16, 2)] <- 1
rrep <- rep(0, 16)
rrep[c(1,2,5,6,9,10,13,14)] <- 1
reprep <- as.numeric(trep==rrep & trep == 1)
swrep <- as.numeric(trep!=rrep & trep == 0)
repsw <- as.numeric(trep!=rrep & trep == 1)
swsw <- as.numeric(trep==rrep & trep == 0)
# binding must be done in the pre-made function to see in the different panels
#swCost <- contrast(estMeans, method = list("Sw_costs" = tsw - trep))
# RR_cocoa: Check if resp sw cost in task switch are different in cocoa = 300 and = 0
swrep0 <- c(swrep[c(1:8)], rep(0,8))
swrep300 <- c(rep(0,8), swrep[c(9:16)])
swsw0 <- c(swsw[c(1:8)], rep(0,8))
swsw300 <- c(rep(0,8), swsw[c(9:16)])
# DR_bind: Check distractor-resp binding in task rep: delta betw resp rep and sw when context rep or sw
# repreprep = task rep + resp rep + context rep
repreprep <- c(reprep[1:4], rep(0,4), reprep[9:12], rep(0,4))
repswrep <- c(repsw[1:4], rep(0,4), repsw[9:12], rep(0,4))
reprepsw <- c(rep(0,4), reprep[5:8], rep(0,4), reprep[13:16])
repswsw <-  c(rep(0,4), repsw[5:8], rep(0,4), repsw[13:16])
# respSw_cocoa: Check diff in the lowest panel: resp switch & context switch in task rep with cocoa 300 or 0
zero <- rep(0,16)
zero[7] <- 1
trec <- rep(0,16)
trec[15] <- 1
# check if task-resp binding is significantly smaller in panel 3 than in 1 in Study 1 (no)
repreprep0 <- c(repreprep[1:8], rep(0,8))
swreprep0 <- c(0, 1, rep(0, 14))
repswrep0 <- c(repswrep[1:8], rep(0,8))
swswrep0 <- c(rep(0,3), 1, rep(0, 12))
reprepsw0 <- c(reprepsw[1:8], rep(0,8))
swrepsw0 <- c(rep(0,5), 1, rep(0, 10))
repswsw0 <- c(repswsw[1:8], rep(0,8))
swswsw0 <- c(rep(0,7), 1, rep(0, 8))
# check if task-resp binding is significantly smaller in panel 4 than in 2 in Study 2 ()
sumM <- summary(estMeans)
repreprep300 <- as.numeric(sumM$task_R == 0 & sumM$ANSWER_R == 0 & sumM$context_R == 0 & sumM$cocoa == 300)
swreprep300 <- as.numeric(sumM$task_R == 1 & sumM$ANSWER_R == 0 & sumM$context_R == 0 & sumM$cocoa == 300)
repswrep300 <- as.numeric(sumM$task_R == 0 & sumM$ANSWER_R == 1 & sumM$context_R == 0 & sumM$cocoa == 300)
swswrep300 <- as.numeric(sumM$task_R == 1 & sumM$ANSWER_R == 1 & sumM$context_R == 0 & sumM$cocoa == 300)
reprepsw300 <- as.numeric(sumM$task_R == 0 & sumM$ANSWER_R == 0 & sumM$context_R == 1 & sumM$cocoa == 300)
swrepsw300 <- as.numeric(sumM$task_R == 1 & sumM$ANSWER_R == 0 & sumM$context_R == 1 & sumM$cocoa == 300)
repswsw300 <- as.numeric(sumM$task_R == 0 & sumM$ANSWER_R == 1 & sumM$context_R == 1 & sumM$cocoa == 300)
swswsw300 <- as.numeric(sumM$task_R == 1 & sumM$ANSWER_R == 1 & sumM$context_R == 1 & sumM$cocoa == 300)
# Run
B
(B == "B1" | B == "B2")
# Emmeans ---------------------------------------------------------------------------------------------
# Calculate marginal means
if (B == "B1" | B == "B2"){
estMeans <- emmeans(mod2, c("task_R", "ANSWER_R", "context_R", "cocoa"), lmer.df = "satterthwaite",
data = drt, type = "response")
} else if (B== "B1B2"){
estMeans <- emmeans(
mod2, c("task_R", "ANSWER_R", "cocoa", "context_R", "exp"), lmer.df = "satterthwaite", data = drt,
type = "response")
}
# Check what emmeans does - not the same as the one below, it takes into account the other variables and, for each
# it first creates a group for each comb of ALL the variables, and then average them acc.ng the require vars
# Plo
# Run the contrasts all together to adjust for multiple comparisons
# binding must be done outside
tot <- contrast(estMeans, method = list("RR_cocoa" = (swrep0 - swsw0) - (swrep300 - swsw300),
#"DR_bind" = (repswrep - repreprep) - (repswsw -reprepsw),
"respSw_cocoa" = zero - trec,
"bindingPanel1vs3" = ((swreprep0-repreprep0) - (swswrep0-repswrep0))
- ((swrepsw0-reprepsw0) - (swswsw0-repswsw0)),
"RRcost_taskSw_contSw_0" = swrepsw0 - swswsw0,
"delta_RRcost_swsw_0vs300" = (swrepsw0 - swswsw0) - (swrepsw300 - swswsw300),
"respRep_swsw_0vs300" = swrepsw300 - swrepsw0,
"taskSwCost_repsw_0vs300" = (swrepsw0 - reprepsw0) - (swrepsw300 - reprepsw300),
"taskSwCost_respsw0_contextSwvsRep" = (swswsw0 - repswsw0) - (swswrep0 - repswrep0),
"taskSwCost_swsw0_0vs300" = (swswsw0 - repswsw0) - (swswsw300 - repswsw300),
"delta_RRbenefit_0taskrep_contSwVsRep" = (repswrep0 - repreprep0) - (repswsw0 - reprepsw0)
))
# Prepare Contrasts RTs ---------------------------------------------------------------------------------------
# Build custom contrasts
# https://aosmith.rbind.io/2019/04/15/custom-contrasts-emmeans/
# Compare the Delta of the task sw cost in resp rep and resp sw --> same as interaction of the mdel
# take the estMeans and build vectors that "pick" the specific condition
trep <- rep(0, 16)
trep[seq(1, 16, 2)] <- 1
rrep <- rep(0, 16)
rrep[c(1,2,5,6,9,10,13,14)] <- 1
reprep <- as.numeric(trep==rrep & trep == 1)
swrep <- as.numeric(trep!=rrep & trep == 0)
repsw <- as.numeric(trep!=rrep & trep == 1)
swsw <- as.numeric(trep==rrep & trep == 0)
# binding must be done in the pre-made function to see in the different panels
#swCost <- contrast(estMeans, method = list("Sw_costs" = tsw - trep))
# RR_cocoa: Check if resp sw cost in task switch are different in cocoa = 300 and = 0
swrep0 <- c(swrep[c(1:8)], rep(0,8))
swrep300 <- c(rep(0,8), swrep[c(9:16)])
swsw0 <- c(swsw[c(1:8)], rep(0,8))
swsw300 <- c(rep(0,8), swsw[c(9:16)])
# DR_bind: Check distractor-resp binding in task rep: delta betw resp rep and sw when context rep or sw
# repreprep = task rep + resp rep + context rep
repreprep <- c(reprep[1:4], rep(0,4), reprep[9:12], rep(0,4))
repswrep <- c(repsw[1:4], rep(0,4), repsw[9:12], rep(0,4))
reprepsw <- c(rep(0,4), reprep[5:8], rep(0,4), reprep[13:16])
repswsw <-  c(rep(0,4), repsw[5:8], rep(0,4), repsw[13:16])
# respSw_cocoa: Check diff in the lowest panel: resp switch & context switch in task rep with cocoa 300 or 0
zero <- rep(0,16)
zero[7] <- 1
trec <- rep(0,16)
trec[15] <- 1
# check if task-resp binding is significantly smaller in panel 3 than in 1 in Study 1 (no)
repreprep0 <- c(repreprep[1:8], rep(0,8))
swreprep0 <- c(0, 1, rep(0, 14))
repswrep0 <- c(repswrep[1:8], rep(0,8))
swswrep0 <- c(rep(0,3), 1, rep(0, 12))
reprepsw0 <- c(reprepsw[1:8], rep(0,8))
swrepsw0 <- c(rep(0,5), 1, rep(0, 10))
repswsw0 <- c(repswsw[1:8], rep(0,8))
swswsw0 <- c(rep(0,7), 1, rep(0, 8))
# check if task-resp binding is significantly smaller in panel 4 than in 2 in Study 2 ()
sumM <- summary(estMeans)
repreprep300 <- as.numeric(sumM$task_R == 0 & sumM$ANSWER_R == 0 & sumM$context_R == 0 & sumM$cocoa == 300)
swreprep300 <- as.numeric(sumM$task_R == 1 & sumM$ANSWER_R == 0 & sumM$context_R == 0 & sumM$cocoa == 300)
repswrep300 <- as.numeric(sumM$task_R == 0 & sumM$ANSWER_R == 1 & sumM$context_R == 0 & sumM$cocoa == 300)
swswrep300 <- as.numeric(sumM$task_R == 1 & sumM$ANSWER_R == 1 & sumM$context_R == 0 & sumM$cocoa == 300)
reprepsw300 <- as.numeric(sumM$task_R == 0 & sumM$ANSWER_R == 0 & sumM$context_R == 1 & sumM$cocoa == 300)
swrepsw300 <- as.numeric(sumM$task_R == 1 & sumM$ANSWER_R == 0 & sumM$context_R == 1 & sumM$cocoa == 300)
repswsw300 <- as.numeric(sumM$task_R == 0 & sumM$ANSWER_R == 1 & sumM$context_R == 1 & sumM$cocoa == 300)
swswsw300 <- as.numeric(sumM$task_R == 1 & sumM$ANSWER_R == 1 & sumM$context_R == 1 & sumM$cocoa == 300)
# Run Contrasts RTs -------------------------------------------------------------------------------------------
# Acco
# Run the contrasts all together to adjust for multiple comparisons
# binding must be done outside
tot <- contrast(estMeans, method = list("RR_cocoa" = (swrep0 - swsw0) - (swrep300 - swsw300),
#"DR_bind" = (repswrep - repreprep) - (repswsw -reprepsw),
"respSw_cocoa" = zero - trec,
"bindingPanel1vs3" = ((swreprep0-repreprep0) - (swswrep0-repswrep0))
- ((swrepsw0-reprepsw0) - (swswsw0-repswsw0)),
"RRcost_taskSw_contSw_0" = swrepsw0 - swswsw0,
"delta_RRcost_swsw_0vs300" = (swrepsw0 - swswsw0) - (swrepsw300 - swswsw300),
"respRep_swsw_0vs300" = swrepsw300 - swrepsw0,
"taskSwCost_repsw_0vs300" = (swrepsw0 - reprepsw0) - (swrepsw300 - reprepsw300),
"taskSwCost_respsw0_contextSwvsRep" = (swswsw0 - repswsw0) - (swswrep0 - repswrep0),
"taskSwCost_swsw0_0vs300" = (swswsw0 - repswsw0) - (swswsw300 - repswsw300),
"delta_RRbenefit_0taskrep_contSwVsRep" = (repswrep0 - repreprep0) - (repswsw0 - reprepsw0)
))
tot
