assign(nam, meansXpp1[meansXpp1$correctResp_R == r & meansXpp1$colour_R == c &
meansXpp1$cocoa == co, "meanmeanrt"])
}}}
# test
if (B == "B1"){
postHocLst <- list(
# dissect task x resp interaction
t.test(t1.r0.c0.0 - t0.r0.c0.0, t1.r1.c0.0 - t0.r1.c0.0, var.equal = T, paired =  T),
t.test(t1.r0.c1.0 - t0.r0.c1.0, t1.r1.c1.0 - t0.r1.c1.0, var.equal = T, paired =  T),
t.test(t1.r0.c0.300 - t0.r0.c0.300, t1.r1.c0.300 - t0.r1.c0.300, var.equal = T, paired =  T),
t.test(t1.r0.c1.300 - t0.r0.c1.300, t1.r1.c1.300 - t0.r1.c1.300, var.equal = T, paired =  T),
# dissect resp x context x cocoa: resp switch cost in context rep vs sw in cocoa 0 or 300
t.test(r1.c0.0 - r0.c0.0, r1.c1.0 - r0.c1.0, var.equal = T, paired =  T),
t.test(r1.c0.300 - r0.c0.300, r1.c1.300 - r0.c1.300, var.equal = T, paired =  T),
)
}
meansXpp <- as.data.frame(group_my(drt, rt, pp, task_R, correctResp_R, colour_R, cocoa))
# retrieve vectors of the means
lev = c(0,1)
for (t in lev){for (r in lev){for (c in lev){for (co in c(0, 300)){
nam <- paste0("t", t, ".r", r, ".c", c, ".", co)
assign(nam, meansXpp[meansXpp$task_R == t & meansXpp$correctResp_R == r & meansXpp$colour_R == c &
meansXpp$cocoa == co, "meanrt"])
}}}}
# further averaging for some post-hocs
meansXpp1 <- as.data.frame(group_my(meansXpp, meanrt, pp, correctResp_R, colour_R, cocoa))
# retrieve vectors of the means
for (r in lev){for (c in lev){for (co in c(0, 300)){
nam <- paste0("r", r, ".c", c, ".", co)
assign(nam, meansXpp1[meansXpp1$correctResp_R == r & meansXpp1$colour_R == c &
meansXpp1$cocoa == co, "meanmeanrt"])
}}}
# test
if (B == "B1"){
postHocLst <- list(
# dissect task x resp interaction
t.test(t1.r0.c0.0 - t0.r0.c0.0, t1.r1.c0.0 - t0.r1.c0.0, var.equal = T, paired =  T),
t.test(t1.r0.c1.0 - t0.r0.c1.0, t1.r1.c1.0 - t0.r1.c1.0, var.equal = T, paired =  T),
t.test(t1.r0.c0.300 - t0.r0.c0.300, t1.r1.c0.300 - t0.r1.c0.300, var.equal = T, paired =  T),
t.test(t1.r0.c1.300 - t0.r0.c1.300, t1.r1.c1.300 - t0.r1.c1.300, var.equal = T, paired =  T),
# dissect resp x context x cocoa: resp switch cost in context rep vs sw in cocoa 0 or 300
t.test(r1.c0.0 - r0.c0.0, r1.c1.0 - r0.c1.0, var.equal = T, paired =  T),
t.test(r1.c0.300 - r0.c0.300, r1.c1.300 - r0.c1.300, var.equal = T, paired =  T),
)
}
postHocLst <- list(
# dissect task x resp interaction
t.test(t1.r0.c0.0 - t0.r0.c0.0, t1.r1.c0.0 - t0.r1.c0.0, var.equal = T, paired =  T),
t.test(t1.r0.c1.0 - t0.r0.c1.0, t1.r1.c1.0 - t0.r1.c1.0, var.equal = T, paired =  T),
t.test(t1.r0.c0.300 - t0.r0.c0.300, t1.r1.c0.300 - t0.r1.c0.300, var.equal = T, paired =  T),
t.test(t1.r0.c1.300 - t0.r0.c1.300, t1.r1.c1.300 - t0.r1.c1.300, var.equal = T, paired =  T),
# dissect resp x context x cocoa: resp switch cost in context rep vs sw in cocoa 0 or 300
t.test(r1.c0.0 - r0.c0.0, r1.c1.0 - r0.c1.0, var.equal = T, paired =  T),
t.test(r1.c0.300 - r0.c0.300, r1.c1.300 - r0.c1.300, var.equal = T, paired =  T)
)
postHocLst
postHocLst <- list(
# dissect task x resp interaction
t.test(t1.r0.c0.0 - t0.r0.c0.0, t1.r1.c0.0 - t0.r1.c0.0, var.equal = T, paired =  T),
t.test(t1.r0.c1.0 - t0.r0.c1.0, t1.r1.c1.0 - t0.r1.c1.0, var.equal = T, paired =  T),
t.test(t1.r0.c0.300 - t0.r0.c0.300, t1.r1.c0.300 - t0.r1.c0.300, var.equal = T, paired =  T),
t.test(t1.r0.c1.300 - t0.r0.c1.300, t1.r1.c1.300 - t0.r1.c1.300, var.equal = T, paired =  T),
# dissect resp x context x cocoa: resp switch cost in context rep vs sw in cocoa 0 or 300
"response switch costs modulated by synchr. context" = t.test(r1.c0.0 - r0.c0.0, r1.c1.0 - r0.c1.0, var.equal = T, paired =  T),
t.test(r1.c0.300 - r0.c0.300, r1.c1.300 - r0.c1.300, var.equal = T, paired =  T)
)
postHocLst
View(postHocLst)
postHocLst[5]
# Adjust p-values for multiple comparisons
# Collect p-values
pvec <- vector()
postHocLst[5]$`response switch costs modulated by synchr. context`
postHocLst[[5]]$data.name
View(postHocLst)
names(postHocLst)
pvec <- vector()
for (ii in 1:length(postHocLst)) {pvec <- c(pvec, postHocLst[[ii]]$p.value)}
# Adjust them
adjPValues <- p.adjust(pvec, method = "fdr")
# Collect post-hocs in a df
postHoc_info <- c("Comparison", "Mean of differences", "df", "t-value", "adj. p-value", "p-value")
postHocDf <- data.frame(matrix(NA, nrow = length(postHocLst), ncol = length(postHoc_info)))
names(postHocDf) <- postHoc_info
# Fill in the columns
postHocDf[,"adj. p-value"] <- round(adjPValues, 4)
for (ii in 1:length(postHocLst)){
postHocDf[ii,"Comparison"] <- names(postHocLst)[ii]
#postHocDf[ii,"Comparison"] <- postHocLst[[ii]]$data.name
postHocDf[ii,"Mean of differences"] <- round(postHocLst[[ii]]$estimate, 2)
postHocDf[ii,"df"] <- postHocLst[[ii]]$parameter
postHocDf[ii,"t-value"] <- round(postHocLst[[ii]]$statistic, 2)
postHocDf[ii,"p-value"] <- round(postHocLst[[ii]]$p.value, 4)
}
postHocDf
# test
if (B == "B1"){
postHocLst <- list(
# dissect task x resp interaction
"task switch costs modulated by resp in synchr. context rep" =
t.test(t1.r0.c0.0 - t0.r0.c0.0, t1.r1.c0.0 - t0.r1.c0.0, var.equal = T, paired =  T),
"task switch costs modulated by resp in synchr. context switch" =
t.test(t1.r0.c1.0 - t0.r0.c1.0, t1.r1.c1.0 - t0.r1.c1.0, var.equal = T, paired =  T),
"task switch costs modulated by resp in delayed context rep" =
t.test(t1.r0.c0.300 - t0.r0.c0.300, t1.r1.c0.300 - t0.r1.c0.300, var.equal = T, paired =  T),
"task switch costs modulated by resp in delayed context switch" =
t.test(t1.r0.c1.300 - t0.r0.c1.300, t1.r1.c1.300 - t0.r1.c1.300, var.equal = T, paired =  T),
# dissect resp x context x cocoa: resp switch cost in context rep vs sw in cocoa 0 or 300
"resp switch costs modulated by synchr. context" =
t.test(r1.c0.0 - r0.c0.0, r1.c1.0 - r0.c1.0, var.equal = T, paired =  T),
"resp switch costs modulated by delayed context" =
t.test(r1.c0.300 - r0.c0.300, r1.c1.300 - r0.c1.300, var.equal = T, paired =  T)
)
}
# Adjust p-values for multiple comparisons
# Collect p-values
pvec <- vector()
for (ii in 1:length(postHocLst)) {pvec <- c(pvec, postHocLst[[ii]]$p.value)}
# Adjust them
adjPValues <- p.adjust(pvec, method = "bonferroni")
# Collect post-hocs in a df
postHoc_info <- c("Comparison", "Mean of differences", "df", "t-value", "adj. p-value", "p-value")
postHocDf <- data.frame(matrix(NA, nrow = length(postHocLst), ncol = length(postHoc_info)))
names(postHocDf) <- postHoc_info
# Fill in the columns
postHocDf[,"adj. p-value"] <- round(adjPValues, 4)
for (ii in 1:length(postHocLst)){
postHocDf[ii,"Comparison"] <- names(postHocLst)[ii]
#postHocDf[ii,"Comparison"] <- postHocLst[[ii]]$data.name
postHocDf[ii,"Mean of differences"] <- round(postHocLst[[ii]]$estimate, 2)
postHocDf[ii,"df"] <- postHocLst[[ii]]$parameter
postHocDf[ii,"t-value"] <- round(postHocLst[[ii]]$statistic, 2)
postHocDf[ii,"p-value"] <- round(postHocLst[[ii]]$p.value, 4)
}
postHocDf
#export post-hoc table
write.table(postHocDf, file= paste0(tabDir, B, "_anova_postHoc_RTs", ".csv"), sep = ";", dec = ".",
row.names = F)
# try if this works for your, otherwise load each package with the line below
if(!require(pacman)) install.packages("pacman")
pacman::p_load("haven", "dplyr", "lme4", "reshape2", "ggplot2", "wesanderson")
# 2nd option if first doen's work
# library("haven")
# etc..
select <- dplyr::select
filter <- dplyr::filter
# write the path to your project folder
setwd('C://Users//Elena//Documents//AA_PhD//Projects//BRAC01_BRAC02//BRAC01-FirstOnline')
# define paths to further subfolders in the project folders (create them first)
dataDir = "data//"
figDir = "figures//"
tabDir = "tables//"
logbookDir = paste0(dataDir, "logbooks//")
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
exp = "18755"
version = "(.)*"
file_extesion = ".csv"
data1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+task-in6f", version, file_extesion)
)
data1_files
d <- read.csv2(paste0(dataDir, data1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
d <- d[c(1:nrow(d) - 1), ]
View(d)
demo1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+questionnaire-89vf", version, file_extesion)
)
demo1_files
demo1 <- read.csv(paste0(dataDir, demo1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
demo1 <- demo1[c(1:nrow(demo1) - 1), ]
#d <- data_exp
demo <- demo1
names(d)[which(names(d) == "Event.Index")] <- "eventIndex"
names(d)[which(names(d) == "Participant.Public.ID")] <- "pp"
names(d)[which(names(d) == "Reaction.Time")] <- "rt"
names(d)[which(names(d) == "Zone.Type")] <- "zoneType"
names(d)[which(names(d) == "Zone.Name")] <- "zoneName"
names(d)[which(names(d) == "Spreadsheet Row")] <- "spreadsheetRow"
names(d)[which(names(d) == "Local.Date")] <- "localDate"
names(d)[which(names(d) == "checkpoint.t5ey")] <- "finalCheckpoint"
names(d)[which(names(d) == "checkpoint.7y1f")] <- "finalCheckpoint"
names(d)[which(names(d) == "Participant.Viewport.Size")] <- "ppViewportSize"
names(d)[which(names(d) == "counterbalance.9qvq")] <- "counterbalance"
names(d)[which(names(d) == "Incorrect")] <- "error"
names(d)[which(names(d) == "blockN")] <- "blockNum"
names(d)[which(names(d) == "trialN")] <- "trialNum"
d$pp <- as.factor(d$pp)
d$rt <- as.numeric(d$rt)
d$eventIndex <- as.numeric(d$eventIndex)
d$blockNum <- as.numeric(d$blockNum)
d$trialNum <- as.numeric(d$trialNum)
names(demo)[which(names(demo) == "Question.Key")] <- "questionKey"
names(demo)[which(names(demo) == "Participant.Public.ID")] <- "pp"
# vector that collects duration of experiment for each pp. Then you can extract mean duration in minutes
durations <- rep(0, length(unique(d$pp)))
# create the logbook, a df that will contain demographics and other info for each pp.
logbook_df <- data.frame("pp" = unique(d$pp))
# it also contains a column to signal if a pp is to remove (set to 0 (=accept) as default)
logbook_df$remove <- 0
# contains info about the counterbalance condition of each
logbook_df$mapping <- ""
# and a column for comments
logbook_df$message <- ""
# Loop over pps to check if some events happened...
#... run either the first or the second line:
for (j in unique(d$pp)){
#for (j in newPps){
# preallocate empty strings that will be filled if sth went wrong
screen_mess = ""
weird_duration_mess = ""
finish_mess = ""
#check & save mapping/counterbalance
#print(d[d$pp == j & d$display == "Instructions", c("counterbalance", "greatMap", "oddMap", "magnMap")][1,])
logbook_df[logbook_df$pp == j, "mapping"] <- unique(d[d$pp == j, "counterbalance"])
# did she re-read instructions?
if (sum(d$pp == j & d$Response == "Re-read instructions", na.rm = T) != 0) {
cat("pp ", j, "has read instructions more than once. \n")
}
# did she get to the end?
if (unique(d[d$pp == j, "finalCheckpoint"]) != "demographics done" & unique(d[d$pp == j, "finalCheckpoint"]) != "after demographic"){
cat("pp ", j, " has not gotten to the end.\n" )
finish_mess = paste("pp ", j, " has not gotten to the end.")
} else {
# if she finished, calculate duration
begin <- as.POSIXct(as.character(d[d$pp == j & d$eventIndex == 1, "UTC.Date"]),format="%d/%m/%Y %H:%M:%S")
# choose the 1st or the 2nd couple or rows: the 1st counts duration from instr to end, the 2nd includes time to answer to demogr
# duration excluding demographics
endRow <- which(d$pp == j & d$breakMessage == "## You have completed block 4 out of 4.")
end <- as.POSIXct(as.character(d[endRow, "UTC.Date"]), format="%d/%m/%Y %H:%M:%S")
# duration including demographics
# endRow <- which(demo$pp == j & demo$questionKey == "END QUESTIONNAIRE")
# end <- as.POSIXct(as.character(demo[endRow, "localDate"]), format="%d/%m/%Y %H:%M:%S")
duration <- difftime(end, begin, units = "mins")
durations[which(unique(d$pp) == j)] <- duration
if (duration > 35 | duration < 14) {
cat("pp ", j, " took", duration, "minutes to complete the experiment.\n")
}
# if she finished, check for comments
# did she left any comments?
#if (!is.na(demo[demo$pp == j & demo$questionKey == "comment", "Response"])){
if (demo[demo$pp == j & demo$questionKey == "comment", "Response"] != ""){
cat("pp ", j, "left a comment:", demo[demo$pp == j & demo$questionKey == "comment", "Response"], "\n\n")
}
}
# did she have big enouhg screen?
screenSize <- unique(d[d$pp == j, "ppViewportSize"])
#w = strsplit(as.character(screenSize), 'x')[1]
# get screen height (the width shouldn't be a concern)
h = strsplit(as.character(screenSize), 'x')[[1]][2]
# the minum is derived by some trials using gorilla preview and simultaneosly this website:
# https://whatismyviewport.com/
if (as.integer(h) < 578) {
cat("pp ", j, "screen height was", h,"while the min necessary is 578.\n" )
screen_mess <- paste0("screen height was ", h," while the min necessary is 578;")
}
# did she have some weird trials durations?
if (sum(d$pp == j & d$zoneType == "fixation" & d$rt > 1410, na.rm = T) > 0) {
cat("pp", j, "has had",  sum(d$pp == j & d$zoneType == "fixation" & d$rt > 1410, na.rm = T),
"weird fixations durations \n\n")
weird_duration_mess = paste(
"has had",  sum(d$pp == j & d$zoneType == "fixation" & d$rt > 1410, na.rm = T),
"weird fixations durations;")
}
if (sum(d$pp == j & d$zoneName == "advancementZone" & d$display == "trial" & d$rt > 310, na.rm = T) > 0) {
cat("pp ", j, "has had", sum(
d$pp == j & d$zoneName == "advancementZone" & d$display == "trial" & d$rt > 310, na.rm = T),
"weird cue durations \n\n")
weird_duration_mess = paste(
weird_duration_mess, "has had", sum(d$pp == j & d$zoneName == "advancementZone" & d$display == "trial" & d$rt > 310, na.rm = T), "weird cue durations;")
}
# did she have a loading delay somewhere?
load_delays <- sum(d$pp == j & d$rt == "LOADING DELAY", na.rm = T)
if (load_delays >0) {cat("pp ", j, " has had", load_delays, "loading delays.\n\n")
}
# fill the pp's logbook line with the info collected in the loop
logbook_df[logbook_df$pp == j, "message1"] <- paste0(screen_mess, weird_duration_mess, finish_mess)
# if there are info in the message column, ask if want ot keep the pp or not
if (logbook_df[logbook_df$pp == j, "message1"] != ""){
# the typed answer is written in the remove column
logbook_df[logbook_df$pp == j, "remove"] <- remove_him(j)
}
}
# Preliminary settings --------------------
# try if this works for your, otherwise load each package with the line below
if(!require(pacman)) install.packages("pacman")
pacman::p_load("haven", "dplyr", "lme4", "reshape2", "ggplot2", "wesanderson")
# 2nd option if first doen's work
# library("haven")
# etc..
select <- dplyr::select
filter <- dplyr::filter
# write the path to your project folder
setwd('C://Users//Elena//Documents//AA_PhD//Projects//BRAC01_BRAC02//BRAC01-FirstOnline')
# define paths to further subfolders in the project folders (create them first)
dataDir = "data//"
figDir = "figures//"
tabDir = "tables//"
logbookDir = paste0(dataDir, "logbooks//")
# a .R file with custom functions - define the path to it if different from the working directory
source("C://Users//Elena//Documents//AA_PhD//Projects//expra2020_faces//modelsFun.R")
#
exp = "18755"
version = "(.)*"
file_extesion = ".csv"
data1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+task-in6f", version, file_extesion)
)
d <- read.csv2(paste0(dataDir, data1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
d <- d[c(1:nrow(d) - 1), ]
demo1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+questionnaire-89vf", version, file_extesion)
)
demo1 <- read.csv(paste0(dataDir, demo1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
demo1 <- demo1[c(1:nrow(demo1) - 1), ]
#d <- data_exp
demo <- demo1
names(d)[which(names(d) == "Event.Index")] <- "eventIndex"
names(d)[which(names(d) == "Participant.Public.ID")] <- "pp"
names(d)[which(names(d) == "Reaction.Time")] <- "rt"
names(d)[which(names(d) == "Zone.Type")] <- "zoneType"
names(d)[which(names(d) == "Zone.Name")] <- "zoneName"
names(d)[which(names(d) == "Spreadsheet Row")] <- "spreadsheetRow"
names(d)[which(names(d) == "Local.Date")] <- "localDate"
names(d)[which(names(d) == "checkpoint.t5ey")] <- "finalCheckpoint"
names(d)[which(names(d) == "checkpoint.7y1f")] <- "finalCheckpoint"
names(d)[which(names(d) == "Participant.Viewport.Size")] <- "ppViewportSize"
names(d)[which(names(d) == "counterbalance.9qvq")] <- "counterbalance"
names(d)[which(names(d) == "Incorrect")] <- "error"
names(d)[which(names(d) == "blockN")] <- "blockNum"
names(d)[which(names(d) == "trialN")] <- "trialNum"
d$pp <- as.factor(d$pp)
d$rt <- as.numeric(d$rt)
d$eventIndex <- as.numeric(d$eventIndex)
d$blockNum <- as.numeric(d$blockNum)
d$trialNum <- as.numeric(d$trialNum)
names(demo)[which(names(demo) == "Question.Key")] <- "questionKey"
names(demo)[which(names(demo) == "Participant.Public.ID")] <- "pp"
# vector that collects duration of experiment for each pp. Then you can extract mean duration in minutes
durations <- rep(0, length(unique(d$pp)))
length(unique(d$pp))
# create the logbook, a df that will contain demographics and other info for each pp.
logbook_df <- data.frame("pp" = unique(d$pp))
# it also contains a column to signal if a pp is to remove (set to 0 (=accept) as default)
logbook_df$remove <- 0
# contains info about the counterbalance condition of each
logbook_df$mapping <- ""
# and a column for comments
logbook_df$message <- ""
unique(d$pp)
# Loop over pps to check if some events happened...
#... run either the first or the second line:
for (j in unique(d$pp)){
#for (j in newPps){
# preallocate empty strings that will be filled if sth went wrong
screen_mess = ""
weird_duration_mess = ""
finish_mess = ""
#check & save mapping/counterbalance
#print(d[d$pp == j & d$display == "Instructions", c("counterbalance", "greatMap", "oddMap", "magnMap")][1,])
logbook_df[logbook_df$pp == j, "mapping"] <- unique(d[d$pp == j, "counterbalance"])
# did she re-read instructions?
if (sum(d$pp == j & d$Response == "Re-read instructions", na.rm = T) != 0) {
cat("pp ", j, "has read instructions more than once. \n")
}
# did she get to the end?
if (unique(d[d$pp == j, "finalCheckpoint"]) != "demographics done" & unique(d[d$pp == j, "finalCheckpoint"]) != "after demographic"){
cat("pp ", j, " has not gotten to the end.\n" )
finish_mess = paste("pp ", j, " has not gotten to the end.")
} else {
# if she finished, calculate duration
begin <- as.POSIXct(as.character(d[d$pp == j & d$eventIndex == 1, "UTC.Date"]),format="%d/%m/%Y %H:%M:%S")
# choose the 1st or the 2nd couple or rows: the 1st counts duration from instr to end, the 2nd includes time to answer to demogr
# duration excluding demographics
endRow <- which(d$pp == j & d$breakMessage == "## You have completed block 4 out of 4.")
end <- as.POSIXct(as.character(d[endRow, "UTC.Date"]), format="%d/%m/%Y %H:%M:%S")
# duration including demographics
# endRow <- which(demo$pp == j & demo$questionKey == "END QUESTIONNAIRE")
# end <- as.POSIXct(as.character(demo[endRow, "localDate"]), format="%d/%m/%Y %H:%M:%S")
duration <- difftime(end, begin, units = "mins")
durations[which(unique(d$pp) == j)] <- duration
if (duration > 35 | duration < 14) {
cat("pp ", j, " took", duration, "minutes to complete the experiment.\n")
}
# if she finished, check for comments
# did she left any comments?
#if (!is.na(demo[demo$pp == j & demo$questionKey == "comment", "Response"])){
if (demo[demo$pp == j & demo$questionKey == "comment", "Response"] != ""){
cat("pp ", j, "left a comment:", demo[demo$pp == j & demo$questionKey == "comment", "Response"], "\n\n")
}
}
# did she have big enouhg screen?
screenSize <- unique(d[d$pp == j, "ppViewportSize"])
#w = strsplit(as.character(screenSize), 'x')[1]
# get screen height (the width shouldn't be a concern)
h = strsplit(as.character(screenSize), 'x')[[1]][2]
# the minum is derived by some trials using gorilla preview and simultaneosly this website:
# https://whatismyviewport.com/
if (as.integer(h) < 578) {
cat("pp ", j, "screen height was", h,"while the min necessary is 578.\n" )
screen_mess <- paste0("screen height was ", h," while the min necessary is 578;")
}
# did she have some weird trials durations?
if (sum(d$pp == j & d$zoneType == "fixation" & d$rt > 1410, na.rm = T) > 0) {
cat("pp", j, "has had",  sum(d$pp == j & d$zoneType == "fixation" & d$rt > 1410, na.rm = T),
"weird fixations durations \n\n")
weird_duration_mess = paste(
"has had",  sum(d$pp == j & d$zoneType == "fixation" & d$rt > 1410, na.rm = T),
"weird fixations durations;")
}
if (sum(d$pp == j & d$zoneName == "advancementZone" & d$display == "trial" & d$rt > 310, na.rm = T) > 0) {
cat("pp ", j, "has had", sum(
d$pp == j & d$zoneName == "advancementZone" & d$display == "trial" & d$rt > 310, na.rm = T),
"weird cue durations \n\n")
weird_duration_mess = paste(
weird_duration_mess, "has had", sum(d$pp == j & d$zoneName == "advancementZone" & d$display == "trial" & d$rt > 310, na.rm = T), "weird cue durations;")
}
# did she have a loading delay somewhere?
load_delays <- sum(d$pp == j & d$rt == "LOADING DELAY", na.rm = T)
if (load_delays >0) {cat("pp ", j, " has had", load_delays, "loading delays.\n\n")
}
# fill the pp's logbook line with the info collected in the loop
logbook_df[logbook_df$pp == j, "message1"] <- paste0(screen_mess, weird_duration_mess, finish_mess)
# if there are info in the message column, ask if want ot keep the pp or not
if (logbook_df[logbook_df$pp == j, "message1"] != ""){
# the typed answer is written in the remove column
logbook_df[logbook_df$pp == j, "remove"] <- remove_him(j)
}
}
cat( "mean duration of the experiment was", mean(durations[durations != 0], na.rm = T), "minutes")
View(logbook_df)
View(logbook_df)
names(d)
# identify true counterbalance node:
names(d)[names(d) == "counterbalance.jqly"] <- "trueCounterbal"
exp = "18755"
version = "(.)*"
file_extesion = ".csv"
data1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+task-in6f", version, file_extesion)
)
d <- read.csv2(paste0(dataDir, data1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
d <- d[c(1:nrow(d) - 1), ]
# identify true counterbalance node:
names(d)[names(d) == "counterbalance.jqly"] <- "trueCounterbal"
names(d)[which(names(d) == "Event.Index")] <- "eventIndex"
names(d)[which(names(d) == "Participant.Public.ID")] <- "pp"
names(d)[which(names(d) == "Reaction.Time")] <- "rt"
names(d)[which(names(d) == "Zone.Type")] <- "zoneType"
names(d)[which(names(d) == "Zone.Name")] <- "zoneName"
names(d)[which(names(d) == "Spreadsheet Row")] <- "spreadsheetRow"
names(d)[which(names(d) == "Local.Date")] <- "localDate"
names(d)[which(names(d) == "checkpoint.t5ey")] <- "finalCheckpoint"
names(d)[which(names(d) == "checkpoint.7y1f")] <- "finalCheckpoint"
names(d)[which(names(d) == "Participant.Viewport.Size")] <- "ppViewportSize"
names(d)[which(names(d) == "trueCounterbal")] <- "counterbalance"
names(d)[which(names(d) == "Incorrect")] <- "error"
names(d)[which(names(d) == "blockN")] <- "blockNum"
names(d)[which(names(d) == "trialN")] <- "trialNum"
d$pp <- as.factor(d$pp)
d$rt <- as.numeric(d$rt)
d$eventIndex <- as.numeric(d$eventIndex)
d$blockNum <- as.numeric(d$blockNum)
d$trialNum <- as.numeric(d$trialNum)
names(demo)[which(names(demo) == "Question.Key")] <- "questionKey"
names(demo)[which(names(demo) == "Participant.Public.ID")] <- "pp"
names(d)
d[d$zoneName == "advancementZone" & d$display == "trial" & d$rt > 310, rt]
d[d$zoneName == "advancementZone" & d$display == "trial" & d$rt > 310, "rt"]
View(d)
exp = "18755"
version = "(.)*"
file_extesion = ".csv"
data1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+task-in6f", version, file_extesion)
)
d <- read.csv2(paste0(dataDir, data1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
d <- d[c(1:nrow(d) - 1), ]
View(d)
d <- read.table(paste0(dataDir, data1_files[1]), sep = ";", dec = ".", fileEncoding="UTF-8-BOM")
View(d)
d <- d[c(1:nrow(d) - 1), ]
d <- read.table(paste0(dataDir, data1_files[1]), header = T, sep = ";", dec = ".", fileEncoding="UTF-8-BOM")
d <- d[c(1:nrow(d) - 1), ]
d <- read.table(paste0(dataDir, data1_files[1]), header = F, sep = ";", dec = ".", fileEncoding="UTF-8-BOM")
d <- d[c(1:nrow(d) - 1), ]
data1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+task-in6f", version, file_extesion)
)
data1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+task-in6f", version, file_extesion)
)
data1_files
d <- read.csv2(paste0(dataDir, data1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
d <- d[c(1:nrow(d) - 1), ]
data_exp <- read.csv2(paste0(dataDir, data1_files[2]), sep = ";")
data_exp <- data_exp[c(1:nrow(data_exp) - 1), ]
d <- read.csv2(paste0(dataDir, data1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
d <- d[c(1:nrow(d) - 1), ]
data_exp <- read.csv2(paste0(dataDir, data1_files[2]), sep = ";")
# identify true counterbalance node:
names(d)[names(d) == "counterbalance.jqly"] <- "trueCounterbal"
demo1_files
version = ""
demo1_files <- list.files(
dataDir, pattern = paste0("^d(.)+", exp ,"(.)+questionnaire-89vf", version, file_extesion)
)
demo1 <- read.csv(paste0(dataDir, demo1_files[1]), sep = ";", fileEncoding="UTF-8-BOM")
demo1 <- demo1[c(1:nrow(demo1) - 1), ]
demo2 <- read.csv(paste0(dataDir, demo1_files[2]), sep = ";")
# Save datasets and choose which to parse in the script ----------
d <- rbind(d, data_exp)
